{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Website A/B Testing - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll get another chance to practice your skills at conducting a full A/B test analysis. It will also be a chance to practice your data exploration and processing skills! The scenario you'll be investigating is data collected from the homepage of a music app page for audacity.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "* Analyze the data from a website A/B test to draw relevant conclusions\n",
    "* Explore and analyze web action data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis\n",
    "\n",
    "Start by loading in the dataset stored in the file 'homepage_actions.csv'. Then conduct an exploratory analysis to get familiar with the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Hints:\n",
    "    * Start investigating the id column:\n",
    "        * How many viewers also clicked?\n",
    "        * Are there any anomalies with the data; did anyone click who didn't view?\n",
    "        * Is there any overlap between the control and experiment groups? \n",
    "            * If so, how do you plan to account for this in your experimental design?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>id</th>\n",
       "      <th>group</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-09-24 17:42:27.839496</td>\n",
       "      <td>804196</td>\n",
       "      <td>experiment</td>\n",
       "      <td>view</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-09-24 19:19:03.542569</td>\n",
       "      <td>434745</td>\n",
       "      <td>experiment</td>\n",
       "      <td>view</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-09-24 19:36:00.944135</td>\n",
       "      <td>507599</td>\n",
       "      <td>experiment</td>\n",
       "      <td>view</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-09-24 19:59:02.646620</td>\n",
       "      <td>671993</td>\n",
       "      <td>control</td>\n",
       "      <td>view</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-09-24 20:26:14.466886</td>\n",
       "      <td>536734</td>\n",
       "      <td>experiment</td>\n",
       "      <td>view</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    timestamp      id       group action\n",
       "0  2016-09-24 17:42:27.839496  804196  experiment   view\n",
       "1  2016-09-24 19:19:03.542569  434745  experiment   view\n",
       "2  2016-09-24 19:36:00.944135  507599  experiment   view\n",
       "3  2016-09-24 19:59:02.646620  671993     control   view\n",
       "4  2016-09-24 20:26:14.466886  536734  experiment   view"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code here\n",
    "import pandas as pd\n",
    "# Loading the data and assigning it to a variable name df\n",
    "df = pd.read_csv('homepage_actions.csv')\n",
    "# Display the first 5 rows to understand the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8188.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>564699.749878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>219085.845672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>182988.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>373637.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>566840.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>758078.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>937217.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id\n",
       "count    8188.000000\n",
       "mean   564699.749878\n",
       "std    219085.845672\n",
       "min    182988.000000\n",
       "25%    373637.500000\n",
       "50%    566840.500000\n",
       "75%    758078.000000\n",
       "max    937217.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Understand the statistics of the data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp    0\n",
       "id           0\n",
       "group        0\n",
       "action       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if the data contains missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "control       4264\n",
       "experiment    3924\n",
       "Name: group, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the 'group' column to understand the value counts for control and experiment groups\n",
    "df['group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of viewers who also clicked: 1860\n",
      "Number of viewers who only viewed: 6328\n"
     ]
    }
   ],
   "source": [
    "# Getting the number of viewers who viewed and clicked and those who just viewed but did not click\n",
    "viewers_clicked = df[df['action'] == 'click']['id'].nunique()\n",
    "viewers_viewed = df[df['action'] == 'view']['id'].nunique()\n",
    "print(f\"Number of viewers who also clicked: {viewers_clicked}\")\n",
    "print(f\"Number of viewers who only viewed: {viewers_viewed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        group action  count\n",
      "0     control  click    932\n",
      "1     control   view   3332\n",
      "2  experiment  click    928\n",
      "3  experiment   view   2996\n"
     ]
    }
   ],
   "source": [
    "# Number of viewers who clicked and viewed based on the two groups\n",
    "click_counts = df.groupby(['group', 'action']).size().reset_index(name='count')\n",
    "print(click_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [click, view]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Group actions by 'id' and count the occurrences of 'click' and 'view'\n",
    "action_counts = df.groupby(['id', 'action']).size().unstack(fill_value=0)\n",
    "# Find rows where 'action' is 'click,' but 'view' is not present for the same 'id' to understand anomalies with the data\n",
    "anomalies = action_counts[(action_counts['click'] > 0) & (action_counts['view'] == 0)]\n",
    "print(anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All those clicked viewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Check for overlap between control and experiment groups\n",
    "# Form sets of 'id' values for 'control' and 'experiment' groups\n",
    "id_control = set(df[df['group'] == 'control']['id'])\n",
    "id_experiment = set(df[df['group'] == 'experiment']['id'])\n",
    "\n",
    "# Use intersection of sets to find 'id' values that appear in both 'control' and 'experiment' groups\n",
    "id_overlap = id_control.intersection(id_experiment)\n",
    "\n",
    "# Convert the result to a list\n",
    "id_list_overlap = list(id_overlap)\n",
    "\n",
    "# Print the 'id' values that overlap\n",
    "print(id_list_overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The control and experiment groups do not have any overlapping 'id' values, which is a positive sign for the experimental design. This implies that there are no overlaps of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conduct a Statistical Test\n",
    "\n",
    "Conduct a statistical test to determine whether the experimental homepage was more effective than that of the control group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypotheses:\n",
    "H0: The average effectiveness of the experimental homepage is  less or the same as that of the control homepage (H0: μ_e <= μ_c)\n",
    "\n",
    "\n",
    "Ha: The average effectiveness of the experimental homepage is higher than that of the control homepage (Ha: μ_e > μ_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.9332699751308076, 0.02660147426144761)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "# Separate the data into control and experiment groups\n",
    "control_group = df[df['group'] == 'control']\n",
    "experiment_group = df[df['group'] == 'experiment']\n",
    "\n",
    "# Calculate the number of clicks and total views for each group\n",
    "clicks_control = (control_group['action'] == 'click').sum()\n",
    "views_control = len(control_group)\n",
    "clicks_experiment = (experiment_group['action'] == 'click').sum()\n",
    "views_experiment = len(experiment_group)\n",
    "\n",
    "# Set the significance level (alpha)\n",
    "alpha = 0.05\n",
    "\n",
    "# Perform a one-tailed z-test for proportions\n",
    "z_statistic, p_value = proportions_ztest([clicks_experiment, clicks_control], [views_experiment, views_control], alternative='larger')\n",
    "z_statistic, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe p-value (0.02660147426144761) is less that the selected significance(alpha) level of 0.05, thus we reject the null \\nhypothesis. This implies that the average effectiveness of the experimental homepage is significantly higher than that of\\nthe control homepage.\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The p-value (0.02660147426144761) is less that the selected significance(alpha) level of 0.05, thus we reject the null \n",
    "hypothesis. This implies that the average effectiveness of the experimental homepage is significantly higher than that of\n",
    "the control homepage.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifying Results\n",
    "\n",
    "One sensible formulation of the data to answer the hypothesis test above would be to create a binary variable representing each individual in the experiment and control group. This binary variable would represent whether or not that individual clicked on the homepage; 1 for they did and 0 if they did not. \n",
    "\n",
    "The variance for the number of successes in a sample of a binomial variable with n observations is given by:\n",
    "\n",
    "## $n\\bullet p (1-p)$\n",
    "\n",
    "Given this, perform 3 steps to verify the results of your statistical test:\n",
    "1. Calculate the expected number of clicks for the experiment group, if it had the same click-through rate as that of the control group. \n",
    "2. Calculate the number of standard deviations that the actual number of clicks was from this estimate. \n",
    "3. Finally, calculate a p-value using the normal distribution based on this z-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1:\n",
    "Calculate the expected number of clicks for the experiment group, if it had the same click-through rate as that of the control group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "857.6848030018762"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code here\n",
    "p_control = clicks_control / views_control\n",
    "expected_clicks_experiment = p_control * views_experiment\n",
    "expected_clicks_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2:\n",
    "Calculate the number of standard deviations that the actual number of clicks was from this estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.888551746650283"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code here\n",
    "import numpy as np\n",
    "\n",
    "# Observed number of clicks in the experiment group\n",
    "observed_clicks_experiment = clicks_experiment\n",
    "\n",
    "# Calculate expected variance\n",
    "std_dev = np.sqrt(views_experiment * p_control * (1 - p_control))\n",
    "std_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: \n",
    "Finally, calculate a p-value using the normal distribution based on this z-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0033030672759265522"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code here\n",
    "from scipy.stats import norm\n",
    "z_score = (clicks_experiment - expected_clicks_experiment) / std_dev\n",
    "\n",
    "# Calculate the p-value\n",
    "p_value = 1 - norm.cdf(z_score)\n",
    "\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis:\n",
    "\n",
    "Does this result roughly match that of the previous statistical test?\n",
    "\n",
    "> Comment: Yes, the p_vaue (0.0033030672759265522) of this test roughly match with the p_value (0.02660147426144761) of the previous statistical test. Both p_value at a significant(alpha) level of 0.05 are statistically significant. Both the initial statistical test and the verification process support the conclusion that the experimental homepage is more effective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, you continued to get more practice designing and conducting AB tests. This required additional work preprocessing and formulating the initial problem in a suitable manner. Additionally, you also saw how to verify results, strengthening your knowledge of binomial variables, and reviewing initial statistical concepts of the central limit theorem, standard deviation, z-scores, and their accompanying p-values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
